import streamlit as st
from PIL import Image, ImageOps
import torch
import torch.nn as nn
from torchvision import models, transforms
import json

# -------------------------------
# [1] ê¸°ë³¸ ì„¤ì •
# -------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------------
# [2] ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì¶”ë¡ ìš©)
# -------------------------------
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.2, 0.2, 0.2])
])

# -------------------------------
# [3] í´ë˜ìŠ¤ ë§¤í•‘ ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------
@st.cache_resource
def load_label_map():
    with open("classes_to_idx.json", "r", encoding="utf-8") as f:
        class_to_idx = json.load(f)
    idx_to_class = {v: k for k, v in class_to_idx.items()}
    return idx_to_class

# -------------------------------
# [4] ëª¨ë¸ ì •ì˜ ë° ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------
def load_model(num_classes):
    model = models.resnet34(weights=None)
    for param in model.parameters():
        param.requires_grad = False

    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_ftrs, 1024),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(1024, num_classes)
    )

    model.load_state_dict(torch.load("best_model.pth", map_location=device))
    model.to(device)
    model.eval()
    return model

# -------------------------------
# [5] Streamlit UI
# -------------------------------
st.title("ğŸŒŸ ë‹®ì€ê¼´ ì—°ì˜ˆì¸ ë¶„ë¥˜ê¸° ğŸŒŸ")
st.chat_input("ì„±ëŠ¥ì€ ë§ê°€ì ¸ ë‚´ë ¸ìœ¼ë‹ˆ ì¬ë¯¸ë¡œë§Œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.ã… ^ã… ")
# íŒŒì¼ ì—…ë¡œë“œ ì‹œ
uploaded_file = st.file_uploader("ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!", type=['jpg', 'jpeg', 'png'])

if uploaded_file:
    image = Image.open(uploaded_file).convert('RGB')
    image = ImageOps.exif_transpose(image)
    st.image(image, caption="ì—…ë¡œë“œí•œ ì‚¬ì§„", use_container_width=True)

    # í´ë˜ìŠ¤ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
    idx_to_class = load_label_map()
    num_classes = len(idx_to_class)

    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = load_model(num_classes)

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
    image_tensor = test_transform(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image_tensor)
        pred_idx = output.argmax(dim=1).item()
        pred_name = idx_to_class[pred_idx]

    st.subheader(f"ğŸ“¸ ë‹¹ì‹ ì€ **{pred_name}** ë‹˜ê³¼ ë‹®ì•˜ìŠµë‹ˆë‹¤!")
